{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Video Analysis Model\n",
    "Put project desc here later\n",
    "\n",
    "By: **Noog Troupers**\n",
    "\n",
    "Members: enter later\n"
   ],
   "id": "c9c60a55cd0abf8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load datasets",
   "id": "74f215646d684bfe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T17:00:51.886309Z",
     "start_time": "2025-09-01T16:59:42.242793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline, AutoTokenizer, AutoConfig\n",
    "from torch import nn\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from data import Dataset as dataset\n",
    "\n",
    "# Load video dataset\n",
    "videos = dataset.getVideos()\n",
    "\n",
    "# Load all comments (4.7 million comments use for actual training)\n",
    "# comments = dataset.getAllComments()\n",
    "\n",
    "# Load one comments dataset (~= 1 million comments each use for testing)\n",
    "comments = dataset.getComments(dataset_id = 1)"
   ],
   "id": "e05f0f8dd8d668df",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T16:16:53.468098Z",
     "start_time": "2025-09-01T16:16:53.329436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Used for writing agnostic code later on\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "id": "dbc18cafbb3672d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T17:15:37.589080Z",
     "start_time": "2025-09-01T17:15:37.562078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class TextPreprocessor:\n",
    "    @staticmethod\n",
    "    def remove_stopwords(tokens):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        stemmer = PorterStemmer()\n",
    "        return [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_punctuation(tokens):\n",
    "        return [word for word in tokens if word not in string.punctuation]\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_special_characters(text):\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_spam(text):\n",
    "        text = str(text).lower()\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "        # If text is shorter than 5 characters without emojis consider it spam\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "        if len(text) < 5:\n",
    "            return True\n",
    "\n",
    "        spam_keywords = ['buy now', 'click here', 'subscribe', 'free', 'visit', 'winner', 'win', 'cash', 'prize']\n",
    "\n",
    "        return int(any(keyword in text for keyword in spam_keywords))\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.strip(' ')  # strip whitespaces\n",
    "        text = text.lower()  # lowercase\n",
    "\n",
    "        tokens = word_tokenize(text)\n",
    "        filtered_tokens = self.remove_stopwords(tokens)\n",
    "        stemmed_tokens = self.stem_tokens(filtered_tokens)\n",
    "        punctuation_free_tokens = self.remove_punctuation(stemmed_tokens)\n",
    "        cleaned_text = ' '.join(punctuation_free_tokens)\n",
    "        cleaned_text = self.remove_special_characters(cleaned_text)\n",
    "\n",
    "\n",
    "        return cleaned_text"
   ],
   "id": "d54d5af50502ffaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "539e2e47f2e293a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T16:16:54.433499Z",
     "start_time": "2025-09-01T16:16:54.416469Z"
    }
   },
   "cell_type": "code",
   "source": "videos.head()",
   "id": "7a70adfc6ba99edd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            kind  videoId                publishedAt  channelId  \\\n",
       "0  youtube#video    85806  2024-01-15 00:59:29+00:00      33807   \n",
       "1  youtube#video    30556  2023-10-27 19:32:16+00:00      46650   \n",
       "2  youtube#video    51771  2024-09-28 01:23:22+00:00      14346   \n",
       "3  youtube#video    45298  2023-07-13 15:19:28+00:00      50139   \n",
       "4  youtube#video    43611  2023-04-29 18:47:37+00:00       8143   \n",
       "\n",
       "                                               title description tags  \\\n",
       "0  Unlocking the Benefits of Face Masks for Skin ...         NaN  NaN   \n",
       "1  Get ready for the Magicüíöüíúü§çüíù‚ú® #hydration #glowi...         NaN  NaN   \n",
       "2  #trending #makeup #beautymakeup #yslbeauty #lu...         NaN  NaN   \n",
       "3                              #shortvedio #balayage         NaN  NaN   \n",
       "4  Full Face of Merit Beauty ü§é featuring new Flus...         NaN  NaN   \n",
       "\n",
       "  defaultLanguage defaultAudioLanguage contentDuration  viewCount  likeCount  \\\n",
       "0           en-US                en-US            PT9S       72.0        0.0   \n",
       "1             NaN                  NaN           PT45S      257.0        7.0   \n",
       "2             NaN                en-US           PT19S      164.0        4.0   \n",
       "3             NaN                  NaN           PT14S     1207.0       20.0   \n",
       "4             NaN                   en           PT56S     8647.0      268.0   \n",
       "\n",
       "   favouriteCount  commentCount  \\\n",
       "0             0.0           0.0   \n",
       "1             0.0           0.0   \n",
       "2             0.0           2.0   \n",
       "3             0.0           0.0   \n",
       "4             0.0           7.0   \n",
       "\n",
       "                                     topicCategories  \n",
       "0  ['https://en.wikipedia.org/wiki/Health', 'http...  \n",
       "1  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
       "2  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
       "3  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
       "4  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>videoId</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>defaultLanguage</th>\n",
       "      <th>defaultAudioLanguage</th>\n",
       "      <th>contentDuration</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favouriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>topicCategories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>85806</td>\n",
       "      <td>2024-01-15 00:59:29+00:00</td>\n",
       "      <td>33807</td>\n",
       "      <td>Unlocking the Benefits of Face Masks for Skin ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en-US</td>\n",
       "      <td>en-US</td>\n",
       "      <td>PT9S</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Health', 'http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>30556</td>\n",
       "      <td>2023-10-27 19:32:16+00:00</td>\n",
       "      <td>46650</td>\n",
       "      <td>Get ready for the Magicüíöüíúü§çüíù‚ú® #hydration #glowi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT45S</td>\n",
       "      <td>257.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>51771</td>\n",
       "      <td>2024-09-28 01:23:22+00:00</td>\n",
       "      <td>14346</td>\n",
       "      <td>#trending #makeup #beautymakeup #yslbeauty #lu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en-US</td>\n",
       "      <td>PT19S</td>\n",
       "      <td>164.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>45298</td>\n",
       "      <td>2023-07-13 15:19:28+00:00</td>\n",
       "      <td>50139</td>\n",
       "      <td>#shortvedio #balayage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PT14S</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youtube#video</td>\n",
       "      <td>43611</td>\n",
       "      <td>2023-04-29 18:47:37+00:00</td>\n",
       "      <td>8143</td>\n",
       "      <td>Full Face of Merit Beauty ü§é featuring new Flus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>PT56S</td>\n",
       "      <td>8647.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T17:34:16.046208Z",
     "start_time": "2025-09-01T17:32:59.324425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove duplicates\n",
    "comments = comments.drop_duplicates(subset = [\"commentId\"])\n",
    "videos = videos.drop_duplicates(subset = [\"videoId\"])\n",
    "\n",
    "# Note down spam comments\n",
    "comments[\"isSpam\"] = comments[\"textOriginal\"].apply(TextPreprocessor().is_spam)\n",
    "\n",
    "# Remove spam comments\n",
    "# comments = comments[comments[\"isSpam\"] == 0]\n",
    "# comments = comments.drop(columns = [\"isSpam\"])\n",
    "\n",
    "# Drop rows with missing comment text\n",
    "comments.dropna(inplace = True, subset = [\"textOriginal\"])\n",
    "\n",
    "# Clean comment text (remove stopwords, punctuation, special characters, and lowercase)\n",
    "comments[\"textCleaned\"] = comments[\"textOriginal\"].apply(TextPreprocessor().clean_text)"
   ],
   "id": "bab6a3512d0d13b8",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T17:25:57.663780Z",
     "start_time": "2025-09-01T17:25:57.651442Z"
    }
   },
   "cell_type": "code",
   "source": "comments",
   "id": "6a135b74a66766a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   kind  commentId  channelId  videoId  authorId  \\\n",
       "1       youtube#comment     289571      14727    79618   3043229   \n",
       "18      youtube#comment     211328      17781    87279   2454363   \n",
       "41      youtube#comment     102498      18073    42340   2575009   \n",
       "43      youtube#comment      87579      15536    82053    894013   \n",
       "47      youtube#comment     270594      19550    14405   1198778   \n",
       "...                 ...        ...        ...      ...       ...   \n",
       "999924  youtube#comment     356990       2269    10948   1636508   \n",
       "999943  youtube#comment     315253      11477    69509    693215   \n",
       "999956  youtube#comment     274174      14429    69445    954619   \n",
       "999978  youtube#comment      15670      23872    40538   1969353   \n",
       "999988  youtube#comment     165695      40072    33967   1697242   \n",
       "\n",
       "                                             textOriginal  parentCommentId  \\\n",
       "1        Apply mashed potato juice and mixed it with curd        3198066.0   \n",
       "18      Oh, I'm so glad that you found this channel th...        3686870.0   \n",
       "41                                             Love u‚ù§Ô∏è‚ù§Ô∏è         546184.0   \n",
       "43                                       You‚Äôre welcome üòä        3440022.0   \n",
       "47                                           Thank you! üòä        3477720.0   \n",
       "...                                                   ...              ...   \n",
       "999924  @user-rv6vp4vs5o Thank you I really appreciate...        4499703.0   \n",
       "999943  ‚Äã@@secretsbylavendereven I, a portuguese speak...        3452566.0   \n",
       "999956            You're a good guy with common sense! üëçüèª         888237.0   \n",
       "999978                                       Thank you ‚ò∫Ô∏è        1035150.0   \n",
       "999988                                    @JellyCat12 why        3736351.0   \n",
       "\n",
       "        likeCount                publishedAt                  updatedAt  \\\n",
       "1               0  2023-10-02 13:08:22+00:00  2023-10-02 13:08:22+00:00   \n",
       "18              1  2023-05-09 04:40:28+00:00  2023-05-09 04:40:28+00:00   \n",
       "41              1  2022-03-09 18:17:00+00:00  2022-03-09 18:17:00+00:00   \n",
       "43              0  2021-09-11 08:54:14+00:00  2021-09-11 08:54:14+00:00   \n",
       "47              1  2023-08-17 06:47:46+00:00  2023-08-17 06:47:46+00:00   \n",
       "...           ...                        ...                        ...   \n",
       "999924          1  2024-04-26 12:24:07+00:00  2024-04-26 12:24:07+00:00   \n",
       "999943          0  2023-12-18 22:30:32+00:00  2024-06-04 03:38:26+00:00   \n",
       "999956          1  2023-08-31 12:26:33+00:00  2023-08-31 12:26:33+00:00   \n",
       "999978          1  2020-08-12 08:54:20+00:00  2020-08-12 08:54:20+00:00   \n",
       "999988          0  2022-12-03 02:26:24+00:00  2023-11-04 12:44:58+00:00   \n",
       "\n",
       "                                              cleanedText  \n",
       "1                         appli mash potato juic mix curd  \n",
       "18      oh m glad found channel thank much let know vi...  \n",
       "41                                                 love u  \n",
       "43                                                welcom   \n",
       "47                                                 thank   \n",
       "...                                                   ...  \n",
       "999924               userrv6vp4vs5o thank realli appreci   \n",
       "999943   secretsbylavendereven portugues speaker ca nt...  \n",
       "999956                           re good guy common sens   \n",
       "999978                                             thank   \n",
       "999988                                         jellycat12  \n",
       "\n",
       "[94590 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>commentId</th>\n",
       "      <th>channelId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>parentCommentId</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>cleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>289571</td>\n",
       "      <td>14727</td>\n",
       "      <td>79618</td>\n",
       "      <td>3043229</td>\n",
       "      <td>Apply mashed potato juice and mixed it with curd</td>\n",
       "      <td>3198066.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-10-02 13:08:22+00:00</td>\n",
       "      <td>2023-10-02 13:08:22+00:00</td>\n",
       "      <td>appli mash potato juic mix curd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>211328</td>\n",
       "      <td>17781</td>\n",
       "      <td>87279</td>\n",
       "      <td>2454363</td>\n",
       "      <td>Oh, I'm so glad that you found this channel th...</td>\n",
       "      <td>3686870.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-05-09 04:40:28+00:00</td>\n",
       "      <td>2023-05-09 04:40:28+00:00</td>\n",
       "      <td>oh m glad found channel thank much let know vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>102498</td>\n",
       "      <td>18073</td>\n",
       "      <td>42340</td>\n",
       "      <td>2575009</td>\n",
       "      <td>Love u‚ù§Ô∏è‚ù§Ô∏è</td>\n",
       "      <td>546184.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-09 18:17:00+00:00</td>\n",
       "      <td>2022-03-09 18:17:00+00:00</td>\n",
       "      <td>love u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>87579</td>\n",
       "      <td>15536</td>\n",
       "      <td>82053</td>\n",
       "      <td>894013</td>\n",
       "      <td>You‚Äôre welcome üòä</td>\n",
       "      <td>3440022.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-11 08:54:14+00:00</td>\n",
       "      <td>2021-09-11 08:54:14+00:00</td>\n",
       "      <td>welcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>270594</td>\n",
       "      <td>19550</td>\n",
       "      <td>14405</td>\n",
       "      <td>1198778</td>\n",
       "      <td>Thank you! üòä</td>\n",
       "      <td>3477720.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-17 06:47:46+00:00</td>\n",
       "      <td>2023-08-17 06:47:46+00:00</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999924</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>356990</td>\n",
       "      <td>2269</td>\n",
       "      <td>10948</td>\n",
       "      <td>1636508</td>\n",
       "      <td>@user-rv6vp4vs5o Thank you I really appreciate...</td>\n",
       "      <td>4499703.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-26 12:24:07+00:00</td>\n",
       "      <td>2024-04-26 12:24:07+00:00</td>\n",
       "      <td>userrv6vp4vs5o thank realli appreci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999943</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>315253</td>\n",
       "      <td>11477</td>\n",
       "      <td>69509</td>\n",
       "      <td>693215</td>\n",
       "      <td>‚Äã@@secretsbylavendereven I, a portuguese speak...</td>\n",
       "      <td>3452566.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-18 22:30:32+00:00</td>\n",
       "      <td>2024-06-04 03:38:26+00:00</td>\n",
       "      <td>secretsbylavendereven portugues speaker ca nt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999956</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>274174</td>\n",
       "      <td>14429</td>\n",
       "      <td>69445</td>\n",
       "      <td>954619</td>\n",
       "      <td>You're a good guy with common sense! üëçüèª</td>\n",
       "      <td>888237.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-08-31 12:26:33+00:00</td>\n",
       "      <td>2023-08-31 12:26:33+00:00</td>\n",
       "      <td>re good guy common sens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999978</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>15670</td>\n",
       "      <td>23872</td>\n",
       "      <td>40538</td>\n",
       "      <td>1969353</td>\n",
       "      <td>Thank you ‚ò∫Ô∏è</td>\n",
       "      <td>1035150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-12 08:54:20+00:00</td>\n",
       "      <td>2020-08-12 08:54:20+00:00</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>165695</td>\n",
       "      <td>40072</td>\n",
       "      <td>33967</td>\n",
       "      <td>1697242</td>\n",
       "      <td>@JellyCat12 why</td>\n",
       "      <td>3736351.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-03 02:26:24+00:00</td>\n",
       "      <td>2023-11-04 12:44:58+00:00</td>\n",
       "      <td>jellycat12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94590 rows √ó 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T17:32:49.614012Z",
     "start_time": "2025-09-01T17:32:48.577334Z"
    }
   },
   "cell_type": "code",
   "source": "analyzer = pipeline(\"sentiment-analysis\", model=\"tabularisai/multilingual-sentiment-analysis\")",
   "id": "ad4a686ac6655eb3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T17:36:30.134587Z",
     "start_time": "2025-09-01T17:36:05.305233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analyzer(\"Thank you!\")\n",
    "\n",
    "comments[\"sentiment\"] = comments[\"textCleaned\"].apply(lambda x: analyzer(x)[0]['label'])"
   ],
   "id": "a69500c1e35e891d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (647) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m analyzer(\u001B[33m\"\u001B[39m\u001B[33mThank you!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m comments[\u001B[33m\"\u001B[39m\u001B[33msentiment\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[43mcomments\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtextCleaned\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43manalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlabel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4935\u001B[39m, in \u001B[36mSeries.apply\u001B[39m\u001B[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[39m\n\u001B[32m   4800\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mapply\u001B[39m(\n\u001B[32m   4801\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   4802\u001B[39m     func: AggFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m   4807\u001B[39m     **kwargs,\n\u001B[32m   4808\u001B[39m ) -> DataFrame | Series:\n\u001B[32m   4809\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4810\u001B[39m \u001B[33;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[32m   4811\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4926\u001B[39m \u001B[33;03m    dtype: float64\u001B[39;00m\n\u001B[32m   4927\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m   4928\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4929\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4930\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4931\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4932\u001B[39m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m=\u001B[49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4933\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4934\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m-> \u001B[39m\u001B[32m4935\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001B[39m, in \u001B[36mSeriesApply.apply\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1419\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_compat()\n\u001B[32m   1421\u001B[39m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1422\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001B[39m, in \u001B[36mSeriesApply.apply_standard\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1496\u001B[39m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[32m   1497\u001B[39m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[32m   1498\u001B[39m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[32m   1499\u001B[39m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[32m   1500\u001B[39m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[32m   1501\u001B[39m action = \u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj.dtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1502\u001B[39m mapped = \u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1503\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[32m   1504\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1506\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[32m0\u001B[39m], ABCSeries):\n\u001B[32m   1507\u001B[39m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[32m   1508\u001B[39m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[32m   1509\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj._constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index=obj.index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:925\u001B[39m, in \u001B[36mIndexOpsMixin._map_values\u001B[39m\u001B[34m(self, mapper, na_action, convert)\u001B[39m\n\u001B[32m    922\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[32m    923\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arr.map(mapper, na_action=na_action)\n\u001B[32m--> \u001B[39m\u001B[32m925\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m=\u001B[49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[39m, in \u001B[36mmap_array\u001B[39m\u001B[34m(arr, mapper, na_action, convert)\u001B[39m\n\u001B[32m   1741\u001B[39m values = arr.astype(\u001B[38;5;28mobject\u001B[39m, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1742\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1743\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1745\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m lib.map_infer_mask(\n\u001B[32m   1746\u001B[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001B[32m   1747\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/lib.pyx:2999\u001B[39m, in \u001B[36mpandas._libs.lib.map_infer\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 3\u001B[39m, in \u001B[36m<lambda>\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m      1\u001B[39m analyzer(\u001B[33m\"\u001B[39m\u001B[33mThank you!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m comments[\u001B[33m\"\u001B[39m\u001B[33msentiment\u001B[39m\u001B[33m\"\u001B[39m] = comments[\u001B[33m\"\u001B[39m\u001B[33mtextCleaned\u001B[39m\u001B[33m\"\u001B[39m].apply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43manalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:168\u001B[39m, in \u001B[36mTextClassificationPipeline.__call__\u001B[39m\u001B[34m(self, inputs, **kwargs)\u001B[39m\n\u001B[32m    133\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    134\u001B[39m \u001B[33;03mClassify the text(s) given as inputs.\u001B[39;00m\n\u001B[32m    135\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    165\u001B[39m \u001B[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001B[39;00m\n\u001B[32m    166\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    167\u001B[39m inputs = (inputs,)\n\u001B[32m--> \u001B[39m\u001B[32m168\u001B[39m result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    169\u001B[39m \u001B[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001B[39;00m\n\u001B[32m    170\u001B[39m _legacy = \u001B[33m\"\u001B[39m\u001B[33mtop_k\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1467\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1459\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m   1460\u001B[39m         \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   1461\u001B[39m             \u001B[38;5;28mself\u001B[39m.get_iterator(\n\u001B[32m   (...)\u001B[39m\u001B[32m   1464\u001B[39m         )\n\u001B[32m   1465\u001B[39m     )\n\u001B[32m   1466\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1467\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1474\u001B[39m, in \u001B[36mPipeline.run_single\u001B[39m\u001B[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[39m\n\u001B[32m   1472\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[32m   1473\u001B[39m     model_inputs = \u001B[38;5;28mself\u001B[39m.preprocess(inputs, **preprocess_params)\n\u001B[32m-> \u001B[39m\u001B[32m1474\u001B[39m     model_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1475\u001B[39m     outputs = \u001B[38;5;28mself\u001B[39m.postprocess(model_outputs, **postprocess_params)\n\u001B[32m   1476\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001B[39m, in \u001B[36mPipeline.forward\u001B[39m\u001B[34m(self, model_inputs, **forward_params)\u001B[39m\n\u001B[32m   1372\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[32m   1373\u001B[39m         model_inputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_inputs, device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m-> \u001B[39m\u001B[32m1374\u001B[39m         model_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1375\u001B[39m         model_outputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m   1376\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:199\u001B[39m, in \u001B[36mTextClassificationPipeline._forward\u001B[39m\u001B[34m(self, model_inputs)\u001B[39m\n\u001B[32m    197\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33muse_cache\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m inspect.signature(model_forward).parameters:\n\u001B[32m    198\u001B[39m     model_inputs[\u001B[33m\"\u001B[39m\u001B[33muse_cache\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m199\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:907\u001B[39m, in \u001B[36mDistilBertForSequenceClassification.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    899\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    900\u001B[39m \u001B[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[32m    901\u001B[39m \u001B[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[32m    902\u001B[39m \u001B[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[32m    903\u001B[39m \u001B[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[32m    904\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    905\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m--> \u001B[39m\u001B[32m907\u001B[39m distilbert_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdistilbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    908\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    909\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    910\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    911\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    912\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    913\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    914\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    916\u001B[39m hidden_state = distilbert_output[\u001B[32m0\u001B[39m]  \u001B[38;5;66;03m# (bs, seq_len, dim)\u001B[39;00m\n\u001B[32m    917\u001B[39m pooled_output = hidden_state[:, \u001B[32m0\u001B[39m]  \u001B[38;5;66;03m# (bs, dim)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:713\u001B[39m, in \u001B[36mDistilBertModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    710\u001B[39m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[32m    711\u001B[39m head_mask = \u001B[38;5;28mself\u001B[39m.get_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers)\n\u001B[32m--> \u001B[39m\u001B[32m713\u001B[39m embeddings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[32m    715\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._use_flash_attention_2:\n\u001B[32m    716\u001B[39m     attention_mask = attention_mask \u001B[38;5;28;01mif\u001B[39;00m (attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[32m0\u001B[39m \u001B[38;5;129;01min\u001B[39;00m attention_mask) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\My Drive\\University\\Loreal Datathon\\model_prototype\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:125\u001B[39m, in \u001B[36mEmbeddings.forward\u001B[39m\u001B[34m(self, input_ids, input_embeds)\u001B[39m\n\u001B[32m    121\u001B[39m     position_ids = position_ids.unsqueeze(\u001B[32m0\u001B[39m).expand_as(input_ids)  \u001B[38;5;66;03m# (bs, max_seq_length)\u001B[39;00m\n\u001B[32m    123\u001B[39m position_embeddings = \u001B[38;5;28mself\u001B[39m.position_embeddings(position_ids)  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m embeddings = \u001B[43minput_embeds\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mposition_embeddings\u001B[49m  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n\u001B[32m    126\u001B[39m embeddings = \u001B[38;5;28mself\u001B[39m.LayerNorm(embeddings)  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n\u001B[32m    127\u001B[39m embeddings = \u001B[38;5;28mself\u001B[39m.dropout(embeddings)  \u001B[38;5;66;03m# (bs, max_seq_length, dim)\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: The size of tensor a (647) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
