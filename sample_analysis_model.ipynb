{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DeWfZdCl6-b"
      },
      "source": [
        "# CommentSense: AI-Powered Comment Analysis System\n",
        "\n",
        "**Problem Statement**: Measuring content effectiveness through Share of Engagement (SoE) metrics like likes, shares, saves, and comments is essential. How do we analyze the quality and relevance of comments, at scale?\n",
        "\n",
        "**Solution Features**:\n",
        "- Quality comment ratio analysis\n",
        "- Sentiment breakdown per video\n",
        "- Comment categorization (skincare, fragrance, makeup)\n",
        "- Spam detection\n",
        "- Relevance analysis using distance metrics\n",
        "\n",
        "By: **Noog Troupers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaiXPETwl6-f"
      },
      "source": [
        "## 1. Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:14:38.109924Z",
          "start_time": "2025-09-11T10:14:14.581905Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdNWzLGDl6-g",
        "outputId": "390f086b-83a6-4dc8-8e3c-18ce0b718b43"
      },
      "source": [
        "%load_ext cudf.pandas\n",
        "!pip install aiopandas\n",
        "import aiopandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "!pip install googletrans # for Google Colab\n",
        "from googletrans import Translator\n",
        "import asyncio\n",
        "!pip install langdetect\n",
        "from langdetect import detect\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cudf.pandas extension is already loaded. To reload it, use:\n",
            "  %reload_ext cudf.pandas\n",
            "Requirement already satisfied: aiopandas in /usr/local/lib/python3.12/dist-packages (0.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from aiopandas) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->aiopandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->aiopandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->aiopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->aiopandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->aiopandas) (1.17.0)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.15.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7wv0fVOl6-i"
      },
      "source": [
        "## 2. Data Loading Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:14:38.270245Z",
          "start_time": "2025-09-11T10:14:38.256242Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9PX0ooOl6-i",
        "outputId": "df223f0d-7380-4d66-832d-ed45f4062251"
      },
      "source": [
        "class Dataset:\n",
        "    comment_links = [\n",
        "        \"https://storage.googleapis.com/dataset_hosting/comments1.csv\",\n",
        "        \"https://storage.googleapis.com/dataset_hosting/comments2.csv\",\n",
        "        \"https://storage.googleapis.com/dataset_hosting/comments3.csv\",\n",
        "        \"https://storage.googleapis.com/dataset_hosting/comments4.csv\",\n",
        "        \"https://storage.googleapis.com/dataset_hosting/comments5.csv\",\n",
        "    ]\n",
        "\n",
        "    video_link = \"https://storage.googleapis.com/dataset_hosting/videos.csv\"\n",
        "\n",
        "    @staticmethod\n",
        "    def getAllComments():\n",
        "        list_of_dfs = []\n",
        "        for csv_file in Dataset.comment_links:\n",
        "            df = pd.read_csv(csv_file)\n",
        "            list_of_dfs.append(df)\n",
        "        return pd.concat(list_of_dfs, ignore_index=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def getComments(dataset_id=1, sample_frac=0.1):\n",
        "        if dataset_id not in range(1, len(Dataset.comment_links) + 1):\n",
        "            raise ValueError(f\"dataset_id must be between 1 and {len(Dataset.comment_links)}\")\n",
        "\n",
        "        df = pd.read_csv(Dataset.comment_links[dataset_id - 1])\n",
        "        if sample_frac < 1.0:\n",
        "            df = df.sample(frac=sample_frac, random_state=42)\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def getVideos():\n",
        "        return pd.read_csv(Dataset.video_link)\n",
        "\n",
        "# Initialize dataset\n",
        "dataset = Dataset()\n",
        "print(\"Dataset class initialized successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset class initialized successfully!\n"
          ]
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkvZupRkl6-j"
      },
      "source": [
        "## 3. Advanced Text Preprocessing and Analysis Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:14:38.298761Z",
          "start_time": "2025-09-11T10:14:38.283761Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDZdOrJMl6-k",
        "outputId": "1f111bd1-ed8f-4666-b871-72713621a523"
      },
      "source": [
        "class AdvancedTextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # Beauty category keywords\n",
        "        self.category_keywords = {\n",
        "            'skincare': ['skincare', 'skin', 'moisturizer', 'cleanser', 'serum', 'cream', 'lotion',\n",
        "                        'acne', 'pores', 'wrinkles', 'anti-aging', 'hydrating', 'dry skin', 'oily skin',\n",
        "                        'sensitive skin', 'sunscreen', 'spf', 'retinol', 'vitamin c', 'hyaluronic',\n",
        "                        'exfoliate', 'toner', 'mask', 'facial', 'dermatologist'],\n",
        "\n",
        "            'makeup': ['makeup', 'foundation', 'concealer', 'lipstick', 'eyeshadow', 'mascara',\n",
        "                      'eyeliner', 'blush', 'bronzer', 'highlighter', 'primer', 'setting spray',\n",
        "                      'powder', 'contour', 'brow', 'eyebrow', 'lip gloss', 'lip liner', 'palette',\n",
        "                      'brush', 'beauty blender', 'sponge', 'coverage', 'matte', 'dewy', 'shimmer'],\n",
        "\n",
        "            'fragrance': ['perfume', 'fragrance', 'cologne', 'scent', 'smell', 'aroma', 'notes',\n",
        "                         'floral', 'woody', 'citrus', 'vanilla', 'musk', 'fresh', 'sweet', 'spicy',\n",
        "                         'eau de toilette', 'eau de parfum', 'body spray', 'long lasting',\n",
        "                         'signature scent', 'top notes', 'base notes', 'middle notes']\n",
        "        }\n",
        "\n",
        "        # Spam indicators\n",
        "        self.spam_keywords = [\n",
        "            'buy now', 'click here', 'subscribe', 'free', 'visit', 'winner', 'win', 'cash', 'prize',\n",
        "            'limited time', 'act now', 'urgent', 'amazing deal', 'check out my', 'follow me',\n",
        "            'dm me', 'link in bio', 'promo code', 'discount', '50% off', 'sale'\n",
        "        ]\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean and preprocess text\"\"\"\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            return \"\"\n",
        "\n",
        "        # Convert to lowercase and strip\n",
        "        text = str(text).lower().strip()\n",
        "\n",
        "        # Remove URLs, mentions, hashtags\n",
        "        text = re.sub(r'http\\S+|www\\S+|@\\w+|#\\w+', '', text)\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Remove stopwords and punctuation\n",
        "        tokens = [word for word in tokens if word not in self.stop_words and word not in string.punctuation]\n",
        "\n",
        "        # Stem tokens\n",
        "        tokens = [self.stemmer.stem(word) for word in tokens if len(word) > 2]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    async def translate_text(self, text):\n",
        "        \"\"\"Translate text to English\"\"\"\n",
        "        # Detect if text is English, if so no translation needed\n",
        "        try:\n",
        "            if detect(text) == 'en':\n",
        "                return text\n",
        "        except Exception as e:\n",
        "            return text\n",
        "\n",
        "        # If the text is not English translate it to English\n",
        "        async with Translator() as translator:\n",
        "          try:\n",
        "              translated_obj = await translator.translate(text, dest='en')\n",
        "              return translated_obj.text\n",
        "          except Exception as e:\n",
        "              print(f\"Translation error: {e}\")\n",
        "              return text\n",
        "\n",
        "    async def batch_translate_text(self, texts, batch_size=100):\n",
        "        \"\"\"Translate a list of texts to English in batches\"\"\"\n",
        "        translated_texts = []\n",
        "        async with Translator() as translator:\n",
        "            for i in range(0, len(texts), batch_size):\n",
        "                batch = texts[i:i + batch_size]\n",
        "                try:\n",
        "                    # Filter out empty strings or non-string types before translating\n",
        "                    valid_batch = [text for text in batch if isinstance(text, str) and text.strip()]\n",
        "                    if not valid_batch:\n",
        "                        translated_texts.extend([\"\"] * len(batch)) # Maintain original list length\n",
        "                        continue\n",
        "\n",
        "                    # Detect language for the first item as a proxy\n",
        "                    lang = 'en'\n",
        "                    try:\n",
        "                        lang = detect(valid_batch[0])\n",
        "                    except:\n",
        "                        pass # Assume English if detection fails\n",
        "\n",
        "                    if lang == 'en':\n",
        "                        translated_texts.extend(batch)\n",
        "                    else:\n",
        "                        translated_batch_objs = await translator.translate(valid_batch, dest='en')\n",
        "                        # Ensure translated texts align with the original batch, handling empty inputs\n",
        "                        translated_results = []\n",
        "                        valid_batch_idx = 0\n",
        "                        for original_text in batch:\n",
        "                            if isinstance(original_text, str) and original_text.strip():\n",
        "                                translated_results.append(translated_batch_objs[valid_batch_idx].text)\n",
        "                                valid_batch_idx += 1\n",
        "                            else:\n",
        "                                translated_results.append(\"\") # Append empty string for invalid inputs\n",
        "                        translated_texts.extend(translated_results)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Batch translation error (batch {i//batch_size + 1}): {e}\")\n",
        "                    translated_texts.extend(batch) # Append original texts in case of error\n",
        "\n",
        "        return translated_texts\n",
        "\n",
        "    def detect_spam(self, text):\n",
        "        \"\"\"Detect spam comments with improved logic\"\"\"\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            return 1\n",
        "\n",
        "        text = str(text).lower()\n",
        "\n",
        "        # Remove emojis for length check\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "        text_no_emoji = emoji_pattern.sub('', text)\n",
        "\n",
        "        # Check for very short comments (likely spam/low quality)\n",
        "        if len(text_no_emoji.strip()) < 3:\n",
        "            return 1\n",
        "\n",
        "        # Check for excessive repetition\n",
        "        words = text_no_emoji.split()\n",
        "        if len(words) > 1 and len(set(words)) / len(words) < 0.5:\n",
        "            return 1\n",
        "\n",
        "        # Check for spam keywords\n",
        "        spam_score = sum(1 for keyword in self.spam_keywords if keyword in text)\n",
        "        if spam_score >= 2:\n",
        "            return 1\n",
        "\n",
        "        # Check for excessive caps\n",
        "        if len(text) > 10 and sum(1 for c in text if c.isupper()) / len(text) > 0.7:\n",
        "            return 1\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def categorize_comment(self, text):\n",
        "        \"\"\"Categorize comments into beauty categories\"\"\"\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            return 'other'\n",
        "\n",
        "        text = str(text).lower()\n",
        "        category_scores = {}\n",
        "\n",
        "        for category, keywords in self.category_keywords.items():\n",
        "            score = sum(1 for keyword in keywords if keyword in text)\n",
        "            category_scores[category] = score\n",
        "\n",
        "        if max(category_scores.values()) == 0:\n",
        "            return 'other'\n",
        "\n",
        "        return max(category_scores.keys(), key=category_scores.get)\n",
        "\n",
        "    def assess_quality(self, text, sentiment=None):\n",
        "        \"\"\"Assess comment quality based on multiple factors\"\"\"\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            return 0\n",
        "\n",
        "        text = str(text).lower()\n",
        "        quality_score = 0\n",
        "\n",
        "        # Length factor (reasonable length comments are better)\n",
        "        word_count = len(text.split())\n",
        "        if 5 <= word_count <= 50:\n",
        "            quality_score += 2\n",
        "        elif 3 <= word_count < 5 or 50 < word_count <= 100:\n",
        "            quality_score += 1\n",
        "\n",
        "        # Product relevance\n",
        "        for keywords in self.category_keywords.values():\n",
        "            if any(keyword in text for keyword in keywords):\n",
        "                quality_score += 2\n",
        "                break\n",
        "\n",
        "        # Sentiment consideration\n",
        "        if sentiment and sentiment != 'neutral':\n",
        "            quality_score += 1\n",
        "\n",
        "        # Engagement indicators\n",
        "        engagement_words = ['love', 'amazing', 'recommend', 'favorite', 'best', 'great', 'good', 'bad', 'disappointed']\n",
        "        if any(word in text for word in engagement_words):\n",
        "            quality_score += 1\n",
        "\n",
        "        # Quality threshold\n",
        "        return 1 if quality_score >= 3 else 0\n",
        "\n",
        "print(\"AdvancedTextPreprocessor class created successfully!\")\n",
        "\n",
        "atp = AdvancedTextPreprocessor()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdvancedTextPreprocessor class created successfully!\n",
            "I don't like this product.\n",
            "The picture is a picture is a picture is a picture is a picture is a picture\n",
            "['The picture is a picture is a picture is a picture is a picture is a picture', 'The picture is a picture is a picture is a picture is a picture is a picture', 'The picture is a picture is a picture is a picture is a picture is a picture', 'The picture is a picture is a picture is a picture is a picture is a picture']\n"
          ]
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pXp-G_5l6-l"
      },
      "source": [
        "## 4. Relevance Analysis Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:14:38.348552Z",
          "start_time": "2025-09-11T10:14:38.339722Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDVi-c-3l6-l",
        "outputId": "2a2c47f0-6df8-44a7-f97b-5c0c9a2d217e"
      },
      "source": [
        "class RelevanceAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', ngram_range=(1, 2))\n",
        "\n",
        "    def calculate_relevance_score(self, comment_text, video_title, video_description=\"\", video_tags=\"\"):\n",
        "        \"\"\"Calculate relevance score using cosine similarity\"\"\"\n",
        "        try:\n",
        "            # Combine video content\n",
        "            video_content = f\"{video_title} {video_description} {video_tags}\".strip()\n",
        "\n",
        "            if not comment_text or not video_content:\n",
        "                return 0.0\n",
        "\n",
        "            # Create TF-IDF vectors\n",
        "            texts = [str(comment_text), str(video_content)]\n",
        "            tfidf_matrix = self.vectorizer.fit_transform(texts)\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "\n",
        "            return float(similarity)\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def batch_relevance_analysis(self, comments_df, videos_df):\n",
        "        \"\"\"Perform batch relevance analysis\"\"\"\n",
        "        # Merge comments with video data\n",
        "        merged_df = comments_df.merge(videos_df[['videoId', 'title', 'description', 'tags']],\n",
        "                                     on='videoId', how='left')\n",
        "\n",
        "        # Calculate relevance scores\n",
        "        relevance_scores = []\n",
        "        for _, row in merged_df.iterrows():\n",
        "            score = self.calculate_relevance_score(\n",
        "                row.get('textOriginal', ''),\n",
        "                row.get('title', ''),\n",
        "                row.get('description', ''),\n",
        "                row.get('tags', '')\n",
        "            )\n",
        "            relevance_scores.append(score)\n",
        "\n",
        "        return relevance_scores\n",
        "\n",
        "print(\"RelevanceAnalyzer class created successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RelevanceAnalyzer class created successfully!\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjDznNazl6-m"
      },
      "source": [
        "## 5. Visualization Dashboard Class"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T11:50:13.905726Z",
          "start_time": "2025-09-11T11:50:13.890235Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajNlTKbel6-m",
        "outputId": "91570e9e-fcd1-428d-baaa-155e98029dbf"
      },
      "cell_type": "code",
      "source": [
        "class CommentAnalyticsDashboard:\n",
        "    def __init__(self):\n",
        "        self.colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\n",
        "\n",
        "    def create_quality_ratio_chart(self, df):\n",
        "        \"\"\"Create quality ratio visualization\"\"\"\n",
        "        quality_counts = df['quality_score'].value_counts()\n",
        "\n",
        "        fig = go.Figure(data=[\n",
        "            go.Pie(labels=['Low Quality', 'High Quality'],\n",
        "                   values=[quality_counts.get(0, 0), quality_counts.get(1, 0)],\n",
        "                   hole=0.4,\n",
        "                   marker_colors=['#FF6B6B', '#4ECDC4'])\n",
        "        ])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"Comment Quality Ratio\",\n",
        "            annotations=[dict(text='Quality<br>Ratio', x=0.5, y=0.5, font_size=20, showarrow=False)]\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_sentiment_breakdown(self, df):\n",
        "        \"\"\"Create sentiment breakdown visualization\"\"\"\n",
        "        sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "        fig = px.bar(x=sentiment_counts.index, y=sentiment_counts.values,\n",
        "                     title=\"Sentiment Distribution\",\n",
        "                     labels={'x': 'Sentiment', 'y': 'Count'},\n",
        "                     color=sentiment_counts.index,\n",
        "                     color_discrete_sequence=self.colors)\n",
        "\n",
        "        fig.update_layout(showlegend=False)\n",
        "        return fig\n",
        "\n",
        "    def create_category_breakdown(self, df):\n",
        "        \"\"\"Create category breakdown visualization\"\"\"\n",
        "        category_counts = df['category'].value_counts()\n",
        "\n",
        "        fig = px.pie(values=category_counts.values, names=category_counts.index,\n",
        "                     title=\"Comment Categories\",\n",
        "                     color_discrete_sequence=self.colors)\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_spam_detection_chart(self, df):\n",
        "        \"\"\"Create spam detection visualization\"\"\"\n",
        "        spam_counts = df['isSpam'].value_counts()\n",
        "\n",
        "        fig = go.Figure(data=[\n",
        "            go.Bar(x=['Legitimate', 'Spam'],\n",
        "                   y=[spam_counts.get(0, 0), spam_counts.get(1, 0)],\n",
        "                   marker_color=['#4ECDC4', '#FF6B6B'])\n",
        "        ])\n",
        "\n",
        "        fig.update_layout(title=\"Spam Detection Results\")\n",
        "        return fig\n",
        "\n",
        "    def create_relevance_distribution(self, df):\n",
        "        \"\"\"Create relevance score distribution\"\"\"\n",
        "        fig = px.histogram(df, x='relevance_score',\n",
        "                          title=\"Comment Relevance Score Distribution\",\n",
        "                          labels={'x': 'Relevance Score', 'y': 'Count'})\n",
        "\n",
        "        fig.add_vline(x=df['relevance_score'].mean(), line_dash=\"dash\",\n",
        "                     annotation_text=f\"Mean: {df['relevance_score'].mean():.3f}\")\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_video_analysis_summary(self, df, video_id):\n",
        "        \"\"\"Create per-video analysis summary\"\"\"\n",
        "        video_data = df[df['videoId'] == video_id]\n",
        "\n",
        "        if len(video_data) == 0:\n",
        "            return None\n",
        "\n",
        "        # Create subplot figure\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=('Quality Ratio', 'Sentiment Distribution',\n",
        "                           'Category Breakdown', 'Relevance Scores'),\n",
        "            specs=[[{'type': 'domain'}, {'type': 'xy'}],\n",
        "                   [{'type': 'domain'}, {'type': 'xy'}]]\n",
        "        )\n",
        "\n",
        "        # Quality ratio pie chart\n",
        "        quality_counts = video_data['quality_score'].value_counts()\n",
        "        fig.add_trace(go.Pie(labels=['Low Quality', 'High Quality'],\n",
        "                            values=[quality_counts.get(0, 0), quality_counts.get(1, 0)],\n",
        "                            name=\"Quality\"), row=1, col=1)\n",
        "\n",
        "        # Sentiment bar chart\n",
        "        sentiment_counts = video_data['sentiment'].value_counts()\n",
        "        fig.add_trace(go.Bar(x=sentiment_counts.index, y=sentiment_counts.values,\n",
        "                            name=\"Sentiment\"), row=1, col=2)\n",
        "\n",
        "        # Category pie chart\n",
        "        category_counts = video_data['category'].value_counts()\n",
        "        fig.add_trace(go.Pie(labels=category_counts.index, values=category_counts.values,\n",
        "                            name=\"Category\"), row=2, col=1)\n",
        "\n",
        "        # Relevance histogram\n",
        "        fig.add_trace(go.Histogram(x=video_data['relevance_score'], name=\"Relevance\"),\n",
        "                     row=2, col=2)\n",
        "\n",
        "        fig.update_layout(height=800, title_text=f\"Video Analysis Summary - {video_id}\")\n",
        "\n",
        "        return fig\n",
        "\n",
        "print(\"CommentAnalyticsDashboard class created successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CommentAnalyticsDashboard class created successfully!\n"
          ]
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca3kts-Jl6-n"
      },
      "source": [
        "## 6. Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:15:40.120043Z",
          "start_time": "2025-09-11T10:14:38.438462Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHAFzJIql6-n",
        "outputId": "11cba331-2e9c-45cf-d889-e88fe42d03ec"
      },
      "source": [
        "# Load datasets\n",
        "print(\"Loading video dataset...\")\n",
        "videos = dataset.getVideos()\n",
        "\n",
        "print(\"Loading comments dataset (10% sample for demo)...\")\n",
        "comments = dataset.getComments(dataset_id=1, sample_frac=0.01)\n",
        "\n",
        "print(f\"Loaded {len(videos)} videos and {len(comments)} comments\")\n",
        "\n",
        "# Remove duplicates\n",
        "comments = comments.drop_duplicates(subset=[\"commentId\"])\n",
        "videos = videos.drop_duplicates(subset=[\"videoId\"])\n",
        "\n",
        "# Drop rows with missing comment text\n",
        "comments = comments.dropna(subset=[\"textOriginal\"])\n",
        "\n",
        "print(f\"After cleaning: {len(videos)} videos and {len(comments)} comments\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading video dataset...\n",
            "Loading comments dataset (10% sample for demo)...\n",
            "Loaded 92759 videos and 10000 comments\n",
            "After cleaning: 92759 videos and 10000 comments\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BQn6O-gl6-n"
      },
      "source": [
        "## 7. Advanced Text Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:15:58.588843Z",
          "start_time": "2025-09-11T10:15:40.197404Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6px3n1ol6-o",
        "outputId": "ae964418-87e5-46ef-bfff-e75f7932a92b"
      },
      "source": [
        "# Initialize text preprocessor\n",
        "preprocessor = AdvancedTextPreprocessor()\n",
        "\n",
        "print(\"Performing text preprocessing and analysis...\")\n",
        "\n",
        "# Detect language and translate text to English\n",
        "# print(\"Detecting and translating text to English...\")\n",
        "# translated_texts = await preprocessor.batch_translate_text(comments[\"textOriginal\"].tolist(), batch_size=500)\n",
        "# comments[\"textTranslated\"] = translated_texts\n",
        "\n",
        "# Clean text\n",
        "print(\"Cleaning text...\")\n",
        "comments[\"textCleaned\"] = comments[\"textOriginal\"].apply(preprocessor.clean_text)\n",
        "\n",
        "# Detect spam\n",
        "print(\"Detecting spam comments...\")\n",
        "comments[\"isSpam\"] = comments[\"textOriginal\"].apply(preprocessor.detect_spam)\n",
        "\n",
        "# Categorize comments\n",
        "print(\"Categorizing comments...\")\n",
        "comments[\"category\"] = comments[\"textOriginal\"].apply(preprocessor.categorize_comment)\n",
        "\n",
        "print(\"Text preprocessing completed!\")\n",
        "print(f\"Spam comments detected: {comments['isSpam'].sum()} ({comments['isSpam'].mean()*100:.1f}%)\")\n",
        "print(\"\\nCategory distribution:\")\n",
        "print(comments['category'].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing text preprocessing and analysis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRM77MXVl6-o"
      },
      "source": [
        "## 8. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:32:51.109073Z",
          "start_time": "2025-09-11T10:15:58.600867Z"
        },
        "id": "K3VcufFcl6-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670,
          "referenced_widgets": [
            "f3753372b2884b0f979f2422eca5151b",
            "d89c0343b7b64b61bebd6c9adf257edf",
            "8375038ef280473abeed3b17b4d90f2e",
            "c86dfa1fbef94fceb23edfe33a314310",
            "b94a9bd09d424022b85df57b1c426cd1",
            "c47e35ae020c4a8bbce855511c980506",
            "e0705056643040c0b84d36efa42680d6",
            "0614ec4035b64c26a9666ec2e12b60ef",
            "3172ea0b38bc4a2a827acbb441f8bf44",
            "2321c10a119e40e5b60d39a9669e19df",
            "10d82787f4584f54938f5b93456b5e7c",
            "6d32b4ac28c5446489406794abc896f9",
            "dd235d8005b3453cb216e1333bc49cfe",
            "57acbf3748c2475e9c701e687198ce5e",
            "4c02241ab9cc41d0b95e876d79484b69",
            "e252a651d6b344d49a335f895648374d",
            "2d732e6ee0a649b5a90440f504874f65",
            "e2fafa5a4a0e46819d5bdd1242b4424f",
            "ddfd07f0b032452484c642a0fbee2aca",
            "b689990a91a1450d96739c650bf0d534",
            "c3176e5e10484a17b28c3c6ee80a1dd0",
            "9beb23641a8e4bc798ae1b966bdc4cd9",
            "4167a54abb594ec8a2838497a796563e",
            "e25c755dcea44cc393f7a8918ec51838",
            "30ee11cc65d04e3faca02eba4e84c25f",
            "4d31614337ca4336b8d8ec4a50e4bc8a",
            "70f3027d892842abbff6d665cf018aaf",
            "b1ff6f8dc9e04fac8cc1b93fdf334dd1",
            "df6371bd91994b2db73e64d4cfff7bba",
            "84b2c3fd10394586bbc67966bfa268c2",
            "6c9336ffe04e478f919b716c4c519600",
            "a815af13fd7e4dfdaa69bdd9f0e35781",
            "33a4960357144eb8a00b2bc4cc34f1ee",
            "faccb803d5aa432c8d7997f77eb87b70",
            "7288caee1a3746baa51c9f4c4f192596",
            "2873464dff3e44a79de7bd76bc23def9",
            "86695a3011ba4aac9118803bf3a9c93c",
            "f943cb431e724a31aa08cf88e52dee3f",
            "92563c15a0cd4609ab6c112863095251",
            "c724bec2532f42a99f7d6c149e3f9a50",
            "763fa0a84e4740ca909753def1d29059",
            "e36d5805b7f349d6abba5b6dca644329",
            "6fe8a38f4b794b02a2eb5737a9e5a645",
            "a6bfbac58e20458987e73ee2f6affd89",
            "a18e857af2ab4b61a3a1ed2988575304",
            "2623c3468337482ba3a25ae2549585ba",
            "e3f9c223ccba499c9000eaac56916899",
            "a55341aa7e504cbd86e39e9ec46ccdaf",
            "91d1e8cabf8b486a8e614ac9b11eaa03",
            "c4c6158e2aaa46c1a7cf16c1ec21dd3d",
            "31f1d7005efb4cd886ab864db6c83a26",
            "003ca6f3714b40ebacd6d6ca529221c9",
            "27622b6be450464a93eedfd32c918e24",
            "bd5dc5bff50f42818226309b4daba873",
            "1d1569f59ab94b058afedbfb07131ecf",
            "efbe8f96201b47c59b4217f4b4bb9282",
            "d5fcbc90a2a4430a92d45863abaf35a9",
            "dfbfd3d41aaa4702a2f2d17724d841e4",
            "82def7518b4147958a45cbe94293f51f",
            "abbdfe9353e84084add3be87c0528244",
            "490082238a054488a2303892789dd86d",
            "162855a7ba544fd0af78faf264425271",
            "2ef09268f5534301a3f56857c9b6ed47",
            "32ece727f00c4513a8b9e3dd2bad9e39",
            "c2d520f0c28143f68a2591860e69a2cc",
            "b5d14a3d82e94839a3ff5f6b3043d740"
          ]
        },
        "outputId": "7407e176-eda4-43ff-9036-92c19221e6b2"
      },
      "source": [
        "# Setup sentiment analysis pipeline\n",
        "device_index = 0 if torch.cuda.is_available() else -1\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "print(f\"Initializing sentiment analysis model: {model_name}\")\n",
        "print(f\"Using device: {'GPU' if device_index == 0 else 'CPU'}\")\n",
        "\n",
        "analyzer = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model_name,\n",
        "    truncation=True,\n",
        "    device=device_index,\n",
        ")\n",
        "\n",
        "# Perform batch sentiment analysis\n",
        "print(\"Performing sentiment analysis...\")\n",
        "\n",
        "# Prepare texts for analysis\n",
        "texts_series = comments[\"textCleaned\"].fillna(\"\").astype(str)\n",
        "unique_texts = list(pd.Series(texts_series.unique()))\n",
        "\n",
        "# Batch processing to avoid memory issues\n",
        "batch_size = 64\n",
        "label_map = {}\n",
        "score_map = {}\n",
        "\n",
        "for i in range(0, len(unique_texts), batch_size):\n",
        "    batch = unique_texts[i:i + batch_size]\n",
        "    try:\n",
        "        results = analyzer(batch, truncation=True, max_length=512)\n",
        "        for text, result in zip(batch, results):\n",
        "            label_map[text] = result[\"label\"]\n",
        "            score_map[text] = result[\"score\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
        "        # Handle failed batch by assigning neutral sentiment\n",
        "        for text in batch:\n",
        "            label_map[text] = \"neutral\"\n",
        "            score_map[text] = 0.5\n",
        "\n",
        "# Map results back to dataframe\n",
        "comments[\"sentiment\"] = texts_series.map(label_map)\n",
        "comments[\"sentiment_score\"] = texts_series.map(score_map)\n",
        "\n",
        "print(\"Sentiment analysis completed!\")\n",
        "print(\"\\nSentiment distribution:\")\n",
        "print(comments['sentiment'].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing sentiment analysis model: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
            "Using device: GPU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3753372b2884b0f979f2422eca5151b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d32b4ac28c5446489406794abc896f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4167a54abb594ec8a2838497a796563e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faccb803d5aa432c8d7997f77eb87b70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a18e857af2ab4b61a3a1ed2988575304"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efbe8f96201b47c59b4217f4b4bb9282"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing sentiment analysis...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3809958402.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m    167\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;31m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0m_legacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"top_k\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m                 )\n\u001b[0;32m-> 1448\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"use_cache\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_to_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_legacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1188\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    606\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 512\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 439\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1q29hCtl6-p"
      },
      "source": [
        "## 9. Quality Assessment and Relevance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:35:42.214820Z",
          "start_time": "2025-09-11T10:32:51.363546Z"
        },
        "id": "pSv7yQOUl6-p"
      },
      "source": [
        "# Quality assessment\n",
        "print(\"Assessing comment quality...\")\n",
        "comments[\"quality_score\"] = comments.apply(\n",
        "    lambda row: preprocessor.assess_quality(row[\"textOriginal\"], row[\"sentiment\"]), axis=1\n",
        ")\n",
        "\n",
        "# Relevance analysis\n",
        "print(\"Performing relevance analysis...\")\n",
        "relevance_analyzer = RelevanceAnalyzer()\n",
        "comments[\"relevance_score\"] = relevance_analyzer.batch_relevance_analysis(comments, videos)\n",
        "\n",
        "print(\"Quality assessment and relevance analysis completed!\")\n",
        "print(f\"High quality comments: {comments['quality_score'].sum()} ({comments['quality_score'].mean()*100:.1f}%)\")\n",
        "print(f\"Average relevance score: {comments['relevance_score'].mean():.3f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoQ3mrsdl6-p"
      },
      "source": [
        "## 10. Key Performance Indicators (KPIs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T10:35:42.384078Z",
          "start_time": "2025-09-11T10:35:42.336632Z"
        },
        "id": "SnTJmatvl6-q"
      },
      "source": [
        "def calculate_kpis(df):\n",
        "    \"\"\"Calculate key performance indicators\"\"\"\n",
        "    total_comments = len(df)\n",
        "\n",
        "    kpis = {\n",
        "        'Total Comments': total_comments,\n",
        "        'Quality Comment Ratio': df['quality_score'].mean(),\n",
        "        'Spam Rate': df['isSpam'].mean(),\n",
        "        'Average Relevance Score': df['relevance_score'].mean(),\n",
        "        'Positive Sentiment %': (df['sentiment'] == 'positive').mean() * 100,\n",
        "        'Negative Sentiment %': (df['sentiment'] == 'negative').mean() * 100,\n",
        "        'Neutral Sentiment %': (df['sentiment'] == 'neutral').mean() * 100,\n",
        "        'Skincare Comments %': (df['category'] == 'skincare').mean() * 100,\n",
        "        'Makeup Comments %': (df['category'] == 'makeup').mean() * 100,\n",
        "        'Fragrance Comments %': (df['category'] == 'fragrance').mean() * 100,\n",
        "        'Other Comments %': (df['category'] == 'other').mean() * 100\n",
        "    }\n",
        "\n",
        "    return kpis\n",
        "\n",
        "# Calculate overall KPIs\n",
        "overall_kpis = calculate_kpis(comments)\n",
        "\n",
        "print(\"=== COMMENT ANALYSIS KPIs ===\")\n",
        "for kpi, value in overall_kpis.items():\n",
        "    if '%' in kpi or 'Ratio' in kpi or 'Rate' in kpi or 'Score' in kpi:\n",
        "        print(f\"{kpi}: {value:.2f}%\" if '%' in kpi else f\"{kpi}: {value:.3f}\")\n",
        "    else:\n",
        "        print(f\"{kpi}: {value:,}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkTckwgAl6-r"
      },
      "source": [
        "## 11. Create Interactive Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T11:50:20.626270Z",
          "start_time": "2025-09-11T11:50:20.305621Z"
        },
        "id": "E7P_W-kjl6-r"
      },
      "source": [
        "# Initialize dashboard\n",
        "dashboard = CommentAnalyticsDashboard()\n",
        "\n",
        "# Create visualizations\n",
        "print(\"Creating interactive dashboard...\")\n",
        "\n",
        "# Overall quality ratio\n",
        "quality_fig = dashboard.create_quality_ratio_chart(comments)\n",
        "quality_fig.show()\n",
        "\n",
        "# Sentiment breakdown\n",
        "sentiment_fig = dashboard.create_sentiment_breakdown(comments)\n",
        "sentiment_fig.show()\n",
        "\n",
        "# Category breakdown\n",
        "category_fig = dashboard.create_category_breakdown(comments)\n",
        "category_fig.show()\n",
        "\n",
        "# Spam detection\n",
        "spam_fig = dashboard.create_spam_detection_chart(comments)\n",
        "spam_fig.show()\n",
        "\n",
        "# Relevance distribution\n",
        "relevance_fig = dashboard.create_relevance_distribution(comments)\n",
        "relevance_fig.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJk8tnIhl6-r"
      },
      "source": [
        "## 12. Per-Video Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T11:50:29.805142Z",
          "start_time": "2025-09-11T11:50:29.739261Z"
        },
        "id": "IB3qjNZZl6-s"
      },
      "source": [
        "# Get video-level analytics\n",
        "def get_video_analytics(df):\n",
        "    \"\"\"Generate per-video analytics\"\"\"\n",
        "    video_stats = df.groupby('videoId').agg({\n",
        "        'commentId': 'count',\n",
        "        'quality_score': 'mean',\n",
        "        'isSpam': 'mean',\n",
        "        'relevance_score': 'mean',\n",
        "        'sentiment_score': 'mean'\n",
        "    }).round(3)\n",
        "\n",
        "    video_stats.columns = ['Total_Comments', 'Quality_Ratio', 'Spam_Rate', 'Avg_Relevance', 'Avg_Sentiment_Score']\n",
        "    video_stats = video_stats.sort_values('Total_Comments', ascending=False)\n",
        "\n",
        "    return video_stats\n",
        "\n",
        "video_analytics = get_video_analytics(comments)\n",
        "print(\"=== TOP 10 VIDEOS BY COMMENT COUNT ===\")\n",
        "print(video_analytics.head(10))\n",
        "\n",
        "# Analyze a specific video\n",
        "top_video_id = video_analytics.index[0]\n",
        "print(f\"\\n=== DETAILED ANALYSIS FOR TOP VIDEO: {top_video_id} ===\")\n",
        "\n",
        "video_summary_fig = dashboard.create_video_analysis_summary(comments, top_video_id)\n",
        "if video_summary_fig:\n",
        "    video_summary_fig.show()\n",
        "\n",
        "# Show sample high-quality comments for the top video\n",
        "top_video_comments = comments[comments['videoId'] == top_video_id]\n",
        "high_quality_comments = top_video_comments[\n",
        "    (top_video_comments['quality_score'] == 1) &\n",
        "    (top_video_comments['isSpam'] == 0)\n",
        "].sort_values('relevance_score', ascending=False)\n",
        "\n",
        "print(f\"\\n=== SAMPLE HIGH-QUALITY COMMENTS FROM {top_video_id} ===\")\n",
        "for i, (_, comment) in enumerate(high_quality_comments.head(5).iterrows()):\n",
        "    print(f\"{i+1}. [{comment['sentiment'].upper()}] (Relevance: {comment['relevance_score']:.3f})\")\n",
        "    print(f\"   \\\"{comment['textOriginal'][:100]}...\\\"\")\n",
        "    print(f\"   Category: {comment['category']}\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqi4JU_Sl6-s"
      },
      "source": [
        "## 13. Advanced Analytics and Insights"
      ]
    },
    {
      "metadata": {
        "id": "T0OyiMkll6-s"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Create comprehensive insights\n",
        "def generate_insights(df):\n",
        "    \"\"\"Generate actionable insights from the data\"\"\"\n",
        "    insights = []\n",
        "\n",
        "    # Quality insights\n",
        "    quality_ratio = df['quality_score'].mean()\n",
        "    if quality_ratio < 0.3:\n",
        "        insights.append(f\"Low quality comment ratio ({quality_ratio:.1%}). Consider content strategy review.\")\n",
        "    elif quality_ratio > 0.6:\n",
        "        insights.append(f\"High quality comment ratio ({quality_ratio:.1%}). Great audience engagement!\")\n",
        "\n",
        "    # Spam insights\n",
        "    spam_rate = df['isSpam'].mean()\n",
        "    if spam_rate > 0.2:\n",
        "        insights.append(f\"High spam rate ({spam_rate:.1%}). Implement stricter comment moderation.\")\n",
        "\n",
        "    # Sentiment insights\n",
        "    positive_ratio = (df['sentiment'] == 'positive').mean()\n",
        "    negative_ratio = (df['sentiment'] == 'negative').mean()\n",
        "\n",
        "    if positive_ratio > 0.5:\n",
        "        insights.append(f\"Positive sentiment dominates ({positive_ratio:.1%}). Audience responds well to content.\")\n",
        "    elif negative_ratio > 0.3:\n",
        "        insights.append(f\"High negative sentiment ({negative_ratio:.1%}). Review content strategy.\")\n",
        "\n",
        "    # Category insights\n",
        "    top_category = df['category'].value_counts().index[0]\n",
        "    top_category_pct = df['category'].value_counts(normalize=True).iloc[0]\n",
        "    insights.append(f\" '{top_category}' is the dominant category ({top_category_pct:.1%} of comments).\")\n",
        "\n",
        "    # Relevance insights\n",
        "    avg_relevance = df['relevance_score'].mean()\n",
        "    if avg_relevance < 0.1:\n",
        "        insights.append(f\"Low content relevance ({avg_relevance:.3f}). Comments may be off-topic.\")\n",
        "    elif avg_relevance > 0.3:\n",
        "        insights.append(f\"High content relevance ({avg_relevance:.3f}). Comments align well with video content.\")\n",
        "\n",
        "    return insights\n",
        "\n",
        "insights = generate_insights(comments)\n",
        "\n",
        "print(\"=== KEY INSIGHTS AND RECOMMENDATIONS ===\")\n",
        "for insight in insights:\n",
        "    print(insight)\n",
        "\n",
        "# Category-specific analysis\n",
        "print(\"\\n=== CATEGORY-SPECIFIC QUALITY ANALYSIS ===\")\n",
        "category_quality = comments.groupby('category').agg({\n",
        "    'quality_score': ['mean', 'count'],\n",
        "    'sentiment': lambda x: (x == 'positive').mean(),\n",
        "    'relevance_score': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "category_quality.columns = ['Quality_Ratio', 'Comment_Count', 'Positive_Sentiment_Ratio', 'Avg_Relevance']\n",
        "print(category_quality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omykzfHvl6-t"
      },
      "source": [
        "## 14. Export Results and Summary"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-11T11:51:16.413501Z",
          "start_time": "2025-09-11T11:51:16.348064Z"
        },
        "id": "AmdN0y4Gl6-u"
      },
      "cell_type": "code",
      "source": [
        "# Create final summary dataframe\n",
        "summary_df = comments[[\n",
        "    'videoId', 'commentId', 'textOriginal', 'textCleaned',\n",
        "    'sentiment', 'sentiment_score', 'category',\n",
        "    'quality_score', 'isSpam', 'relevance_score'\n",
        "]].copy()\n",
        "\n",
        "# Add quality labels\n",
        "summary_df['quality_label'] = summary_df['quality_score'].map({0: 'Low Quality', 1: 'High Quality'})\n",
        "summary_df['spam_label'] = summary_df['isSpam'].map({0: 'Legitimate', 1: 'Spam'})\n",
        "\n",
        "print(\"=== FINAL SUMMARY ===\")\n",
        "print(f\"Dataset processed: {len(summary_df):,} comments\")\n",
        "print(f\"Analysis completed successfully!\")\n",
        "\n",
        "# Display sample of processed data\n",
        "print(\"\\n=== SAMPLE PROCESSED DATA ===\")\n",
        "display_cols = ['textOriginal', 'sentiment', 'category', 'quality_label', 'spam_label', 'relevance_score']\n",
        "sample_data = summary_df[display_cols].head(10)\n",
        "print(sample_data.to_string(max_colwidth=50))\n",
        "\n",
        "# Save results (uncomment to save)\n",
        "# summary_df.to_csv('comment_analysis_results.csv', index=False)\n",
        "# video_analytics.to_csv('video_analytics_summary.csv')\n",
        "# print(\"\\nResults saved to CSV files!\")\n",
        "\n",
        "print(\"\\nCommentSense AI Analysis Complete!\")\n",
        "print(\"\\nThe system has successfully analyzed comment quality, sentiment, categories, spam detection, and relevance at scale.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R0pgZRcl6-u"
      },
      "source": [
        "## 15. Model Performance Summary\n",
        "\n",
        "### Features Implemented:\n",
        "1. **Quality Comment Ratio Analysis** - Identifies high vs low quality comments based on multiple factors\n",
        "2. **Sentiment Breakdown** - Positive, negative, neutral sentiment analysis per video\n",
        "3. **Comment Categorization** - Skincare, makeup, fragrance, and other categories\n",
        "4. **Spam Detection** - Advanced spam detection using multiple indicators\n",
        "5. **Relevance Analysis** - Measures comment relevance to video content using cosine similarity\n",
        "6. **Interactive Dashboard** - Visual analytics for easy interpretation\n",
        "7. **Per-Video Analytics** - Detailed breakdown for each video\n",
        "8. **KPI Tracking** - Key performance indicators for content effectiveness\n",
        "\n",
        "### Key Metrics:\n",
        "- **Share of Engagement (SoE)** analysis through comment quality metrics\n",
        "- **Scalable processing** with batch analysis for large datasets\n",
        "- **Real-time insights** with actionable recommendations\n",
        "- **Category-specific analysis** for targeted content strategy\n",
        "\n",
        "This prototype demonstrates a comprehensive AI-powered solution for analyzing comment quality and relevance at scale, enabling data-driven decisions for content strategy optimization."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3753372b2884b0f979f2422eca5151b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d89c0343b7b64b61bebd6c9adf257edf",
              "IPY_MODEL_8375038ef280473abeed3b17b4d90f2e",
              "IPY_MODEL_c86dfa1fbef94fceb23edfe33a314310"
            ],
            "layout": "IPY_MODEL_b94a9bd09d424022b85df57b1c426cd1"
          }
        },
        "d89c0343b7b64b61bebd6c9adf257edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47e35ae020c4a8bbce855511c980506",
            "placeholder": "",
            "style": "IPY_MODEL_e0705056643040c0b84d36efa42680d6",
            "value": "config.json:100%"
          }
        },
        "8375038ef280473abeed3b17b4d90f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0614ec4035b64c26a9666ec2e12b60ef",
            "max": 929,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3172ea0b38bc4a2a827acbb441f8bf44",
            "value": 929
          }
        },
        "c86dfa1fbef94fceb23edfe33a314310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2321c10a119e40e5b60d39a9669e19df",
            "placeholder": "",
            "style": "IPY_MODEL_10d82787f4584f54938f5b93456b5e7c",
            "value": "929/929[00:00&lt;00:00,41.7kB/s]"
          }
        },
        "b94a9bd09d424022b85df57b1c426cd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47e35ae020c4a8bbce855511c980506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0705056643040c0b84d36efa42680d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0614ec4035b64c26a9666ec2e12b60ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3172ea0b38bc4a2a827acbb441f8bf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2321c10a119e40e5b60d39a9669e19df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d82787f4584f54938f5b93456b5e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d32b4ac28c5446489406794abc896f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd235d8005b3453cb216e1333bc49cfe",
              "IPY_MODEL_57acbf3748c2475e9c701e687198ce5e",
              "IPY_MODEL_4c02241ab9cc41d0b95e876d79484b69"
            ],
            "layout": "IPY_MODEL_e252a651d6b344d49a335f895648374d"
          }
        },
        "dd235d8005b3453cb216e1333bc49cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d732e6ee0a649b5a90440f504874f65",
            "placeholder": "",
            "style": "IPY_MODEL_e2fafa5a4a0e46819d5bdd1242b4424f",
            "value": "pytorch_model.bin:100%"
          }
        },
        "57acbf3748c2475e9c701e687198ce5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddfd07f0b032452484c642a0fbee2aca",
            "max": 501045531,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b689990a91a1450d96739c650bf0d534",
            "value": 501045531
          }
        },
        "4c02241ab9cc41d0b95e876d79484b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3176e5e10484a17b28c3c6ee80a1dd0",
            "placeholder": "",
            "style": "IPY_MODEL_9beb23641a8e4bc798ae1b966bdc4cd9",
            "value": "501M/501M[00:08&lt;00:00,95.7MB/s]"
          }
        },
        "e252a651d6b344d49a335f895648374d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d732e6ee0a649b5a90440f504874f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2fafa5a4a0e46819d5bdd1242b4424f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddfd07f0b032452484c642a0fbee2aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b689990a91a1450d96739c650bf0d534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3176e5e10484a17b28c3c6ee80a1dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9beb23641a8e4bc798ae1b966bdc4cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4167a54abb594ec8a2838497a796563e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e25c755dcea44cc393f7a8918ec51838",
              "IPY_MODEL_30ee11cc65d04e3faca02eba4e84c25f",
              "IPY_MODEL_4d31614337ca4336b8d8ec4a50e4bc8a"
            ],
            "layout": "IPY_MODEL_70f3027d892842abbff6d665cf018aaf"
          }
        },
        "e25c755dcea44cc393f7a8918ec51838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ff6f8dc9e04fac8cc1b93fdf334dd1",
            "placeholder": "",
            "style": "IPY_MODEL_df6371bd91994b2db73e64d4cfff7bba",
            "value": "vocab.json:"
          }
        },
        "30ee11cc65d04e3faca02eba4e84c25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b2c3fd10394586bbc67966bfa268c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c9336ffe04e478f919b716c4c519600",
            "value": 1
          }
        },
        "4d31614337ca4336b8d8ec4a50e4bc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a815af13fd7e4dfdaa69bdd9f0e35781",
            "placeholder": "",
            "style": "IPY_MODEL_33a4960357144eb8a00b2bc4cc34f1ee",
            "value": "899k/?[00:00&lt;00:00,31.2MB/s]"
          }
        },
        "70f3027d892842abbff6d665cf018aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ff6f8dc9e04fac8cc1b93fdf334dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6371bd91994b2db73e64d4cfff7bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b2c3fd10394586bbc67966bfa268c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6c9336ffe04e478f919b716c4c519600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a815af13fd7e4dfdaa69bdd9f0e35781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a4960357144eb8a00b2bc4cc34f1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faccb803d5aa432c8d7997f77eb87b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7288caee1a3746baa51c9f4c4f192596",
              "IPY_MODEL_2873464dff3e44a79de7bd76bc23def9",
              "IPY_MODEL_86695a3011ba4aac9118803bf3a9c93c"
            ],
            "layout": "IPY_MODEL_f943cb431e724a31aa08cf88e52dee3f"
          }
        },
        "7288caee1a3746baa51c9f4c4f192596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92563c15a0cd4609ab6c112863095251",
            "placeholder": "",
            "style": "IPY_MODEL_c724bec2532f42a99f7d6c149e3f9a50",
            "value": "merges.txt:"
          }
        },
        "2873464dff3e44a79de7bd76bc23def9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763fa0a84e4740ca909753def1d29059",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e36d5805b7f349d6abba5b6dca644329",
            "value": 1
          }
        },
        "86695a3011ba4aac9118803bf3a9c93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fe8a38f4b794b02a2eb5737a9e5a645",
            "placeholder": "",
            "style": "IPY_MODEL_a6bfbac58e20458987e73ee2f6affd89",
            "value": "456k/?[00:00&lt;00:00,23.5MB/s]"
          }
        },
        "f943cb431e724a31aa08cf88e52dee3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92563c15a0cd4609ab6c112863095251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c724bec2532f42a99f7d6c149e3f9a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "763fa0a84e4740ca909753def1d29059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e36d5805b7f349d6abba5b6dca644329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fe8a38f4b794b02a2eb5737a9e5a645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6bfbac58e20458987e73ee2f6affd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18e857af2ab4b61a3a1ed2988575304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2623c3468337482ba3a25ae2549585ba",
              "IPY_MODEL_e3f9c223ccba499c9000eaac56916899",
              "IPY_MODEL_a55341aa7e504cbd86e39e9ec46ccdaf"
            ],
            "layout": "IPY_MODEL_91d1e8cabf8b486a8e614ac9b11eaa03"
          }
        },
        "2623c3468337482ba3a25ae2549585ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c6158e2aaa46c1a7cf16c1ec21dd3d",
            "placeholder": "",
            "style": "IPY_MODEL_31f1d7005efb4cd886ab864db6c83a26",
            "value": "model.safetensors:100%"
          }
        },
        "e3f9c223ccba499c9000eaac56916899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_003ca6f3714b40ebacd6d6ca529221c9",
            "max": 500982668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27622b6be450464a93eedfd32c918e24",
            "value": 500982668
          }
        },
        "a55341aa7e504cbd86e39e9ec46ccdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5dc5bff50f42818226309b4daba873",
            "placeholder": "",
            "style": "IPY_MODEL_1d1569f59ab94b058afedbfb07131ecf",
            "value": "501M/501M[00:09&lt;00:00,62.6MB/s]"
          }
        },
        "91d1e8cabf8b486a8e614ac9b11eaa03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c6158e2aaa46c1a7cf16c1ec21dd3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f1d7005efb4cd886ab864db6c83a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "003ca6f3714b40ebacd6d6ca529221c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27622b6be450464a93eedfd32c918e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd5dc5bff50f42818226309b4daba873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1569f59ab94b058afedbfb07131ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efbe8f96201b47c59b4217f4b4bb9282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5fcbc90a2a4430a92d45863abaf35a9",
              "IPY_MODEL_dfbfd3d41aaa4702a2f2d17724d841e4",
              "IPY_MODEL_82def7518b4147958a45cbe94293f51f"
            ],
            "layout": "IPY_MODEL_abbdfe9353e84084add3be87c0528244"
          }
        },
        "d5fcbc90a2a4430a92d45863abaf35a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490082238a054488a2303892789dd86d",
            "placeholder": "",
            "style": "IPY_MODEL_162855a7ba544fd0af78faf264425271",
            "value": "special_tokens_map.json:100%"
          }
        },
        "dfbfd3d41aaa4702a2f2d17724d841e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef09268f5534301a3f56857c9b6ed47",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32ece727f00c4513a8b9e3dd2bad9e39",
            "value": 239
          }
        },
        "82def7518b4147958a45cbe94293f51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d520f0c28143f68a2591860e69a2cc",
            "placeholder": "",
            "style": "IPY_MODEL_b5d14a3d82e94839a3ff5f6b3043d740",
            "value": "239/239[00:00&lt;00:00,21.9kB/s]"
          }
        },
        "abbdfe9353e84084add3be87c0528244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490082238a054488a2303892789dd86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162855a7ba544fd0af78faf264425271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ef09268f5534301a3f56857c9b6ed47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ece727f00c4513a8b9e3dd2bad9e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2d520f0c28143f68a2591860e69a2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d14a3d82e94839a3ff5f6b3043d740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}